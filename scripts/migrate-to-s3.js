import { createClient } from '@supabase/supabase-js';
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
import { fromIni } from '@aws-sdk/credential-providers';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

// ESMì—ì„œ __dirname ì‚¬ìš©í•˜ê¸°
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// .env íŒŒì¼ ë¡œë“œ
dotenv.config({ path: path.join(__dirname, '..', '.env') });

// ì„¤ì •
const BATCH_SIZE = 10;
const TARGET_BUCKET = 'cdn.y3c.kr';
const TARGET_DIR = 'tongkidari/edited-contents/';
const LOCAL_OUTPUT_DIR = path.join(__dirname, 'temp-images');
const AWS_PROFILE = 'yeboc';
const AWS_REGION = 'ap-northeast-2';

// Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
const supabaseUrl = process.env.VITE_SUPABASE_URL;
const supabaseKey = process.env.VITE_SUPABASE_ANON_KEY;

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ Error: VITE_SUPABASE_URL and VITE_SUPABASE_ANON_KEY must be set in .env');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

// AWS S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
const s3Client = new S3Client({
  region: AWS_REGION,
  credentials: fromIni({ profile: AWS_PROFILE }),
});

// ë¡œì»¬ ë””ë ‰í† ë¦¬ ìƒì„±
if (!fs.existsSync(LOCAL_OUTPUT_DIR)) {
  fs.mkdirSync(LOCAL_OUTPUT_DIR, { recursive: true });
  console.log(`ğŸ“ Created local directory: ${LOCAL_OUTPUT_DIR}`);
}

// Base64ë¥¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
function saveBase64AsImage(resourceId, base64Data) {
  const filePath = path.join(LOCAL_OUTPUT_DIR, `${resourceId}.png`);

  // base64 ë°ì´í„°ì—ì„œ prefix ì œê±°
  const base64String = base64Data.includes(',') ? base64Data.split(',')[1] : base64Data;

  // Bufferë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ ì €ì¥
  const buffer = Buffer.from(base64String, 'base64');
  fs.writeFileSync(filePath, buffer);

  return filePath;
}

// S3ì— íŒŒì¼ ì—…ë¡œë“œ
async function uploadToS3(resourceId, filePath) {
  const fileBuffer = fs.readFileSync(filePath);
  const key = `${TARGET_DIR}${resourceId}.png`;

  const command = new PutObjectCommand({
    Bucket: TARGET_BUCKET,
    Key: key,
    Body: fileBuffer,
    ContentType: 'image/png',
  });

  await s3Client.send(command);
  return key;
}

// ë°°ì¹˜ ì²˜ë¦¬
async function processBatch(offset, batchSize) {
  console.log(`\nğŸ“¦ Processing batch: offset=${offset}, size=${batchSize}`);

  // Supabaseì—ì„œ ë°ì´í„° ì¡°íšŒ (LIMITì™€ OFFSET ì‚¬ìš©)
  const { data, error } = await supabase
    .from('edited_contents')
    .select('resource_id, base64')
    .range(offset, offset + batchSize - 1);

  if (error) {
    console.error('âŒ Error fetching data:', error);
    throw error;
  }

  if (!data || data.length === 0) {
    return 0;
  }

  console.log(`   Retrieved ${data.length} items`);

  let successCount = 0;
  let failCount = 0;

  for (const item of data) {
    try {
      const { resource_id, base64 } = item;

      // 1. ë¡œì»¬ì— ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
      const localPath = saveBase64AsImage(resource_id, base64);
      console.log(`   ğŸ’¾ Saved locally: ${resource_id}.png`);

      // 2. S3ì— ì—…ë¡œë“œ
      const s3Key = await uploadToS3(resource_id, localPath);
      console.log(`   â˜ï¸  Uploaded to S3: ${s3Key}`);

      // 3. ë¡œì»¬ íŒŒì¼ ì‚­ì œ (ì„ íƒì‚¬í•­)
      fs.unlinkSync(localPath);

      successCount++;
    } catch (error) {
      console.error(`   âŒ Failed to process ${item.resource_id}:`, error.message);
      failCount++;
    }
  }

  console.log(`   âœ… Success: ${successCount}, âŒ Failed: ${failCount}`);

  return data.length;
}

// ë©”ì¸ í•¨ìˆ˜
async function main() {
  console.log('ğŸš€ Starting migration to S3...\n');
  console.log(`Configuration:`);
  console.log(`  - Supabase URL: ${supabaseUrl}`);
  console.log(`  - S3 Bucket: ${TARGET_BUCKET}`);
  console.log(`  - S3 Directory: ${TARGET_DIR}`);
  console.log(`  - AWS Profile: ${AWS_PROFILE}`);
  console.log(`  - Batch Size: ${BATCH_SIZE}`);
  console.log(`  - Local Output: ${LOCAL_OUTPUT_DIR}`);

  let offset = 0;
  let totalProcessed = 0;
  let batchNumber = 1;

  try {
    while (true) {
      console.log(`\nğŸ“‹ Batch ${batchNumber}:`);

      const processedCount = await processBatch(offset, BATCH_SIZE);

      if (processedCount === 0) {
        console.log('\nâœ¨ No more data to process');
        break;
      }

      totalProcessed += processedCount;
      offset += BATCH_SIZE;
      batchNumber++;

      // ì ì‹œ ëŒ€ê¸° (API rate limit ë°©ì§€)
      await new Promise(resolve => setTimeout(resolve, 1000));
    }

    console.log('\n' + '='.repeat(50));
    console.log(`ğŸ‰ Migration completed!`);
    console.log(`   Total items processed: ${totalProcessed}`);
    console.log('='.repeat(50));

  } catch (error) {
    console.error('\nâŒ Migration failed:', error);
    process.exit(1);
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main();
